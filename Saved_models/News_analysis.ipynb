{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f958e0b-2854-48bc-b461-168b15311000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e24cd0-b2d4-4175-88c6-b30463ba94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\chara\\Downloads\\abcnews-date-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d616e6-aa7d-4952-8103-8fbab96f9a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244184 entries, 0 to 1244183\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   text    1244184 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['publish_date'], axis=1)\n",
    "df = df.rename(columns={'headline_text': 'text'})\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Check the data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5be726-4762-46d6-9122-1de7ed20bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730ca5c7-4b47-44f6-a92d-41227e438444",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 2\n",
    "NEUTRAL = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f092a4a-557c-49f2-8423-68db43cdcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a preprocessor function to determine polarity using VADER\n",
    "@preprocessor(memoize=True)\n",
    "def vader_sentiment(x):\n",
    "    scores = analyzer.polarity_scores(x.text)\n",
    "    x.compound = scores['compound']\n",
    "    return x\n",
    "\n",
    "# Labeling function using VADER compound score\n",
    "@labeling_function(pre=[vader_sentiment])\n",
    "def vader_polarity(x):\n",
    "    if x.compound >= 0.05:\n",
    "        return POSITIVE\n",
    "    elif x.compound <= -0.05:\n",
    "        return NEGATIVE\n",
    "    else:\n",
    "        return NEUTRAL\n",
    "\n",
    "# Additional keyword-based labeling functions\n",
    "@labeling_function()\n",
    "def keyword_positive(x):\n",
    "    keywords = [\"good\", \"great\", \"excellent\", \"positive\", \"fortunate\", \"correct\", \"superior\"]\n",
    "    return POSITIVE if any(word in x.text.lower() for word in keywords) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def keyword_negative(x):\n",
    "    keywords = [\"bad\", \"terrible\", \"awful\", \"negative\", \"unfortunate\", \"wrong\", \"inferior\"]\n",
    "    return NEGATIVE if any(word in x.text.lower() for word in keywords) else ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a691ad8-1930-4778-929b-f469614ba65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1244184/1244184 [21:53<00:00, 947.00it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|                                                                                       | 0/100 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.296]\n",
      "  8%|██████▎                                                                        | 8/100 [00:00<00:01, 78.75epoch/s]INFO:root:[10 epochs]: TRAIN:[loss=0.162]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.035]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.001]\n",
      " 43%|█████████████████████████████████                                            | 43/100 [00:00<00:00, 234.33epoch/s]INFO:root:[50 epochs]: TRAIN:[loss=0.002]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[70 epochs]: TRAIN:[loss=0.000]\n",
      " 79%|████████████████████████████████████████████████████████████▊                | 79/100 [00:00<00:00, 289.61epoch/s]INFO:root:[80 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[90 epochs]: TRAIN:[loss=0.000]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 275.76epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Combine all the labeling functions\n",
    "lfs = [vader_polarity, keyword_positive, keyword_negative]\n",
    "\n",
    "# Apply the LFs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_snorkel = applier.apply(df=df)\n",
    "\n",
    "# Apply the label model\n",
    "label_model = LabelModel(cardinality=3, verbose=True)\n",
    "label_model.fit(L_snorkel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf704440-28d7-4adf-a528-94d191666c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = label_model.predict(L=L_snorkel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77af7a73-8ed8-4c0f-a300-ec3756f08a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.label.isin([0, 1, 2]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983f3994-73a6-4afc-992e-01ae25e8bfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    562599\n",
       "2    425745\n",
       "1    255840\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61627a37-7117-4589-b09b-7ee6fbff070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store headlines and labels in respective lists\n",
    "text = list(df['text'])\n",
    "labels = list(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4baaa28c-3952-47ee-9dce-4ee5c0a6aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "training_text = text[:400000]\n",
    "testing_text = text[400000:600000]\n",
    "training_labels = labels[:400000]\n",
    "testing_labels = labels[400000:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "540931c2-69fb-4b35-bc8e-f1dbfe1bef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_text)\n",
    "training_sequences = tokenizer.texts_to_sequences(training_text)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=120, padding='post', truncating='post')\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_text)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=120, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b2cb799-a64f-43ad-9bfc-f04d184a548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists into numpy arrays to make it work with TensorFlow\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f343ca-5dc9-449f-8f22-cc5330955e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88a6a06e-8e5f-40ed-8fad-a04d5f347fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "554c7164-5e97-4dd8-85b1-ae31be5c2393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "073c3623-f9c2-479b-a718-fca8a73f8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12500/12500 - 62s - 5ms/step - accuracy: 0.7523 - loss: 0.5889 - val_accuracy: 0.9267 - val_loss: 0.2871\n",
      "Epoch 2/10\n",
      "12500/12500 - 61s - 5ms/step - accuracy: 0.9304 - loss: 0.2414 - val_accuracy: 0.9303 - val_loss: 0.2519\n",
      "Epoch 3/10\n",
      "12500/12500 - 62s - 5ms/step - accuracy: 0.9445 - loss: 0.1978 - val_accuracy: 0.8679 - val_loss: 0.3589\n",
      "Epoch 4/10\n",
      "12500/12500 - 62s - 5ms/step - accuracy: 0.9497 - loss: 0.1784 - val_accuracy: 0.9506 - val_loss: 0.1809\n",
      "Epoch 5/10\n",
      "12500/12500 - 63s - 5ms/step - accuracy: 0.9555 - loss: 0.1567 - val_accuracy: 0.9548 - val_loss: 0.1630\n",
      "Epoch 6/10\n",
      "12500/12500 - 63s - 5ms/step - accuracy: 0.9585 - loss: 0.1447 - val_accuracy: 0.9583 - val_loss: 0.1549\n",
      "Epoch 7/10\n",
      "12500/12500 - 61s - 5ms/step - accuracy: 0.9603 - loss: 0.1376 - val_accuracy: 0.9490 - val_loss: 0.1712\n",
      "Epoch 8/10\n",
      "12500/12500 - 63s - 5ms/step - accuracy: 0.9617 - loss: 0.1322 - val_accuracy: 0.9536 - val_loss: 0.1732\n",
      "Epoch 9/10\n",
      "12500/12500 - 63s - 5ms/step - accuracy: 0.9638 - loss: 0.1256 - val_accuracy: 0.9595 - val_loss: 0.1478\n",
      "Epoch 10/10\n",
      "12500/12500 - 61s - 5ms/step - accuracy: 0.9644 - loss: 0.1232 - val_accuracy: 0.9607 - val_loss: 0.1485\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "history = model.fit(training_padded, \n",
    "                    training_labels, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(testing_padded, testing_labels), \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d910a53-8383-4e9c-9367-8f68f5545867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Predicted label: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "def predict_label(model, tokenizer, text, max_len=120):\n",
    "    # Preprocess the input text\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    padded_seqs = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "    \n",
    "    # Predict the class probabilities\n",
    "    prediction = model.predict(padded_seqs)\n",
    "    \n",
    "    # Convert probabilities to class label\n",
    "    class_labels = {0: 'NEUTRAL', 1: 'POSITIVE', 2: 'NEGATIVE'}\n",
    "    predicted_label = class_labels[np.argmax(prediction)]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "new_text = \"The US imposes sanctions on Russia because of the Ukrainian war\"\n",
    "predicted_label = predict_label(model, tokenizer, new_text)\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa6405bf-01a7-43ca-8ee0-6e0e46aad1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77d6a463-95fe-45b0-a900-39fdcc797dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step\n",
      "Accuracy: 0.9565\n",
      "Precision: 0.9567\n",
      "Recall: 0.9565\n",
      "F1 Score: 0.9563\n"
     ]
    }
   ],
   "source": [
    "def calculate_error(model, tokenizer, texts, labels, max_len=120):\n",
    "    # Convert texts to sequences and pad them\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_seqs = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "    \n",
    "    # Predict class probabilities\n",
    "    predictions = model.predict(padded_seqs)\n",
    "    \n",
    "    # Convert probabilities to class labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Example usage\n",
    "accuracy, precision, recall, f1 = calculate_error(model, tokenizer, testing_text, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7991029-73b9-4006-849d-f07ef193b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\chara\\Documents\\sentiment_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d512cf3f-86a0-42e8-91ce-a41f50e65f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the tokenizer to a file\n",
    "with open(r'C:\\Users\\chara\\Documents\\tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d9db0b-e4c7-405e-89b4-d49c3ae42cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m compiled_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mmetrics_names\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompiled Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, compiled_metrics)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "compiled_metrics = model.metrics_names\n",
    "print(\"Compiled Metrics:\", compiled_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce22f56-4b6f-4c37-98fe-234cb6d2c812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
